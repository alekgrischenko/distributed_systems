* Sharding -- patterns and antipatterns
https://habrahabr.ru/company/oleg-bunin/blog/313366/
Константин Осипов, Алексей Рыбак

Нет одного универсального решения, когда за вас работает автоматика, а вы только кофе на работе пьете и все.

Есть проблемы больших баз данных, которые включают:
- replication
- sharding and re-sharding
- distributed queries, jobs, map/reduce
- DDL (data definition language?)

Самая сложная проблема в распределенной системе — это проблема членства,
т.е. кто в нее входит, кто не входит,
потому что машины выходят из строя, происходят ошибки,
и постоянное членство в распределенной системе меняется.

Мы возьмем одну тему,
как какой-то объем данных, который не помещается на одну машину,
можно распределить горизонтально по горизонтальному кластеру,
и как этим всем потом управлять.

Шардинг — это метод горизонтального разделения данных.


** Sharding function
выбор функции шардинга

f(x) = y
x - key
y - shard

В общем случае должна быть функция от ключа и от количества серверов.
И она должна выдавать нужный сервер, потому что она по-разному работает на разном количестве серверов.

Вы выбираете ключ, по которому шардите данные один раз,
и живете с ним всю жизнь, ну или долго — несколько лет,
и получаете все преимущества и недостатки этого дела.
Вы должны выбрать достаточно маленький объект.

История из 2001. SpyLOG (сейчас Openstate).
Собирает статистику посещений сайтов.
Сайты распределены по 40 машинам. Ключом был ID сайта.
Крупные сайты (анекдот.ру, рамблер, яндекс) генерировали трафик больше, чем одна машина могла принять.

Второй пример -- фейсбук. Нельзя делать шардинг по пользователям,
потому что Джастин Бибер сгенерирует слишком много данных.
Будет неоднородное распределение данных, и, придется вводить шардинг второго уровня.

При выборе ключа нужно смотреть на на данные, а на сценарии использования.
Выбор ключа -- компромисс. Часть сценариев он сделает быстрыми (вся инфа в одном шарде),
а часть медленными (инфу нужно будет собирать по нескольким шардам).

В течение последних, наверное, десяти лет многие команды прошли один и тот же путь изобретения велосипедов.

Когда делается большая система, самое важное, это стоимость поддержки —
сколько проблем при эксплуатации всего этого хозяйства возникает.
Поэтому удобство системного администратора — это ценность,
которая должна стоять, наверное, на первом месте.


** Наиболее распространенные и не самых плохие методы

*** Способ 1й

Так, у вас есть один сервер.
Вы подняли реплику, среплицировали на него данные, через какое-то время распределили нагрузку, в том числе по записи.
И думаете, что делать дальше.
А дальше вы покупаете еще два сервера, у каждого из них появляется своя реплика.
Почему реплика? Потому что с точки зрения системного администрирования это достаточно просто —
вы настроили реплику, потом на какое-то время там запретили записи,
таким образом, вы просто делитесь как амеба.

Проблема заключается в том, что вам нужно все время удваиваться, а это будет очень дорого.
2,4,8,out of money.


*** Способ 2й

Чем удобно число 48? Оно делится на 12, на 6, на 4, на 3.
Вы можете начать с того, что на одном сервере будете держать 48 схем или 48 таблиц, порезанных изначально на такое число.
После чего простыми для системного администратора операциями, дампами, вы можете переливать какую-то часть данных на другие сервера.
Можно легко расти до 48 серверов. (Или можно выбрать другое число).

Любая система растет, но ее рост замедляется по мере того, как она становится крупнее. И у нее есть потолок.
Поэтому не всегда нужно брать какие-то самые сложные решения, чтобы все максимально масштабировать.
Если вы знаете, что у вас будет максимум 10 серверов, возможно, вам нужно простое решение.


*** Routing для этих вариантов

Если это числовой ключ, его можно просто поделить на число серверов, получить остаток от деления — и это будет номер вашего сервера.
Если это строковой ключ, например, e-mail, то от него можно взять числовой хэш, далее сделать то же самое.

Тут решардинг является ключевой проблемой.

У вас вылетает нода, вам нужно поднять из реплик мастер-ноду максимально быстро.
Второе — у вас просто нагрузка выросла, вам нужно докупить новые сервера и максимально быстро ввести их в строй.

Если вы просто берете остаток от деления, то все данные нужно передвинуть.
Это очень тяжелая и плохая операция.
Это неплохо работает, когда вы держите все в памяти.

Например, у нас есть кластер memcached в Badoo.
Мы распределили все по остатку от деления, добавили новых серверов (это происходит не так часто),
и через, может быть, 5-10 минут все данные пересортировались.


** Варианты для взрослых

*** Table functions

virtual buckets: key -> bucket -> shard
key->bucket (function), bucket->shard (table/config)
key->bucket (table/config), bucket->shard (table/config)

Сначала вы отображаете ключ на некоторый виртуальный bucket,
потом виртуальный bucket — на соответствующую координату в пространстве вашего кластера.

Виртуальные bucket-ы, как правило, выбираются в достаточно большом количестве.
Почему они виртуальные? Потому что на самом деле они не отражают реального физического сервера.

У вас появляется некое состояние (table/config). Это состояние вам нужно где-то хранить, его нужно менять.


*** Consistent hashing

Мы представляем, что весь диапазон нашей хэш-функции отображается не на прямую от 0 до 2^32 (~ 4 млрд.), а на кольцо.

Мы хэш-функцию применяем и к идентификатору сервера, и также располагаем сервера на этом кольце.
Таким образом, получается, что каждый сервер отвечает за некий диапазон ключей после него на кольце.
Соответственно, когда вы добавляете новый сервер, он забирает те диапазоны,
которые находятся перед ним и после него, т.е. он частично делит диапазон.
(не очень понятное объяснение)

Идея здесь такая: в консистентном хэшировании при добавлении новых нод вы перетасовываете только небольшую часть ключей.

Это не обеспечивает в простом случае идеального распределения.
Для того чтобы консистентное хэширование работало правильно,
еще нужно добавлять некое состояние в виде виртуальных bucket-ов, таблиц отображения.
А виртуальные bucket-ы нужно где-то хранить.

Guava/Sumbur
f(key, num_servers) = server_id
равномерно распределяет ключи по серверам
не имеет состояния


** Routing

Типы роутинга:
- Smart Client
- Proxy
- Coordinator
- Intra-Database Routing
- Local Proxy on every app server


*** Smart Client

table function/config находятся на клиенте

+ нет лишних переходов, клиент сразу запрашивает нужный сервер
- все клиенты (для разных платформ) должны реализовать это
- ре-шардинг становится большой проблемой (все клиенты нужно обновить)


*** Proxy

Сервис-балансировщик, который принимает все запросы от клиентов, и направляет их на другие сервера.

- лишний переход и лишний трафик
- +1 сервер
- SPOF


*** Coordinator

Централизованое место хранения метаинфы о кластере.
- SPOF

Координатор — это просто такой классный парень,
который очень быстро отвечает на простые вопросы «Куда мне идти?».
После этого клиент сам устанавливает соединение и идет на нужную дата-ноду.


*** Intra-Database Routing

А здесь уже мегасложная история.
Допустим, вы не хотите, чтобы у вас были прокси, и хотите, чтобы база данных была очень умная и сама все роутила.
Представьте себе торренты — это будет очень похожая аналогия.

Т.е. нод очень много, данных очень много.
Вы не знаете состояние всего кластера, потому что постоянно меняются ноды.
Тогда вы можете использовать роутинг внутри вашего кластера, внутри самой базы данных.

Идея такая — нода знает своих соседей и какой-то случайный узел в кластере, который не является соседом.
На любую ноду приходит ключ. Нода может посмотреть, ее ли это ключ, и ключ ли это ее соседей слева и справа.
Если нет, то она форвардит ключ на известный ей рандомный узел.
Этот процесс сходится за логарифмическое время, и получается не так много хопов.

Такие технологии используются в очень больших базах данных,
где у вас 100 тысяч узлов и более, и вы не можете где бы то ни было хранить эту информацию.


** Re-Sharding

Ре-шардинг это всегда больно, потому что нужно передвигать огромное количество данных.
Передвижение больших данных — это всегда достаточно большое окно —
время, на которое мы должны выключить какую-то часть системы.
При этом клиенты не должны этого заметить.

Идеальный вариант -- вообще не перемещать данные.
Лучший вариант -- перемещать без участия админов.


*** update is a move

Идея следющая — всегда, когда вы меняете кокой-то ключ, вы его неявно двигаете.
Допустим, у вас ключ шардинга — это, собственно, ключ шардинга и timestamp.
Когда вы меняете данные, вы меняете timestamp, и он у вас естественным образом оказывается на другом шарде.
Вы можете в какой-то момент закрыть апдейты на определенный шард и рано или поздно просто его вывести из строя.
Т.е. очень просто передвигать данные, очень просто выводить данные из строя.


*** data expiration

Memcached в Badoo.
Просто добавили несколько серверов, данные естественным образом устарели — получилась новая схема шардинга.
Годится везде, где данные устаревают и удаляются.

Автоматически появляются на вашем кластере горячая и холодная части,
и может оказаться, что если вы неправильно подобрали какие-то конфигурации или веса,
что горячая часть будет очень маленькой.

Тут две проблемы:
- горячая часть может не справится с нагрузкой
- холодная часть (большая часть кластера) простаивает, не используется

В twitter изначально новые твитты лились на новые ноды.
Когда у них резко возросла нагрузка, потому что люди просто стали больше твиттить,
они внедряли один сервер в неделю, потом понадобилось два сервера в неделю…
В какой-то момент у них админы просто зашивались, нужно было добавлять новые сервера, уже пачками.
В итоге они ушли от этой схемы и теперь старые твитты хранят вместе с новыми.

Третий паттерн здесь очень простой. Он используется в Badoo, и, скорее всего, в гигантском количестве других мест.
Вы добавляете новые сервера и на некоторое время новых пользователей льете только на них.

Мы добавляем новое «железо»,
в конфигураторе говорим, что на старые сервера временно новые данные (новых пользователей) не регистрируем.
Новые пользователи начинают заполнять новые машины,
в результате через какое-то время мы видим, что нагрузки более-менее сравнялись.
После этого мы открываем регистрации на старые сервера,
и таким образом в ручном режиме (не каждодневно, может быть, раз в месяц, в несколько месяцев) просто распределяем нагрузку.


** Из комментов

Под решардингом обычно понимают изменение числа бакетов/vnode.
Перенесение бакетов на другие физические машины обычно называют перебалансировкой.
Это по мотивам терминологии, используемой в документации Couchbase, Cassandra, Riak, CockroachDB
и других СУБД со встроенным шардингом/перебалансировкой.

Мне кажется само собой разумеющимся, что прокси должен быть не в одном экземпляре,
и что «нода» это на самом деле мастер и пара реплик с фейловером (ручным или автоматическим).

На самом деле проблемы с распределением в consistent hashing нет, надо просто дать случайности поработать.
Для этого каждому серверу дают не один а например 256 диапазонов.
И два сервера 512 раз бросив кубик получат красивое деление 50/50.
Добавляется третий сервер, ещё 256 случайностей распределят хэши ровно по трети.
Более того, при этом новый сервер получит примерно по равной части от каждой ноды,
а это значит, что нагрузка на перенос данных будет распределена по всему кластеру.
См. cassandra virtual nodes.
