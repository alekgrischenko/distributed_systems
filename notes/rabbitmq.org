* 101 способ приготовления RabbitMQ и немного о pipeline архитектуре
https://habrahabr.ru/company/oleg-bunin/blog/310418/

Павел Филонов
(его же доклад "Выбираем СУБД для хранения временных рядов", я слушал в живую).

Отличие "события" и "запроса":

С request'ом всегда связан кто-то, кто сидит на той стороне,
тот, кто его отправил, очень нетерпеливый человек, робот, браузер, программа,
он ждет от нас ответа.

Система, которая засылает в нас события, логи, метрики, статистики –
От нас не требуют мгновенного ответа на какой-то вопрос.
От нас просят суметь много и быстро их обработать, обработать их по-разному.

Сколько эта технология проживет?
Если они так быстро появляются, то они начнут примерно с такой же скоростью умирать.

С этой точки зрения RabbitMQ интересен не как продукт, а как технология,
которая опирается на протокол AMQP, более низлежащий слой,
который уже нашел достаточно неплохое свое применение.

Пользователи AMQP:
- Google, вообще, выпускает официальный анонс, что он просто свой SQS-сервис баз строит на основе RabbitMQ.
- Microsoft Azure просто реализует протокол AMQP, реализация у них явно, похоже, своя.
- VMware – один из родоначальников протокола AMQP и системы RabbitMQ, очень активно использует его внутри своих решений.

Преимущества:
- Асинхронная обработка
- Простое добавление обработчиков
- Гибкая маршрутизация
- Удобная отладка
- Масштабируемость читателей и писателей
- Масштабируемость брокера (у RabbitMQ хорошо)
- Устойчивость к перезагрузкам и отказам

Topic в 3 раза медленее Direct.
Consistent Hash быстрый.
Преимущество в том, что он работает с числами. Первые три работают со строками как ключами маршрутизации, а последний работает с числами.

Пакетная обработка. Apache Kafka и ZeroMQ -- из коробки.
(prefetch count -- это не оно?)

Переполнение очередей. Закон Литтла.
- сохранение на диск (чтобы обработать потом)
- блокирование писателей (back-pressure)
- ограничьте размер очередей и/или время жизни сообщений (load-shredding)

Есть встроенный механизм RabbitMQ flow control.
https://www.rabbitmq.com/flow-control.html

Система начинает вставлять случайное ожидание, специальным образом
подобранное при чтении сокета от паблишера, в каком-то смысле уменьшая
уже даже на сетевом уровне интенсивность приходящих от него сетевых
пакетов.

The connection is being blocked and unblocked several times per
second, in order to keep the rate of message ingress at one that the
rest of the server can handle.
From the client's perspective it should just look like the network
bandwidth to the server is lower than it actually is.

Как только очередь возвращается в свои рамки, этот стоп-сигнал убирается, писатель начинает работать в прежнюю силу.

Если это было что-то пиковое, временное, это нас спасет.
Если нет, и эта ситуация постоянна,
мы ее откладываем до самой границы системы – до точки входа.

Stateless filters.
Stateful filters, сумматоры, разного рода агрегаторы.

Способы шардинга:
- остаток от деленая на к-во очередей. Требует константного количества очередей, нельзя добавить/убрать очередь.
- В RabbitMQ есть целых 2 Sharding plugin’а
- consistent-hash-exchange – идет прямо в дефолтной инсталляции,
реализует консистентного хэширования,
позволяет динамически менять количество очередей
старается делать так, чтобы решардинг прошел как можно более мягко.


* Building a Distributed Data Ingestion System with RabbitMQ
https://www.youtube.com/watch?v=EUfSgYU_SFk
https://www.slideshare.net/HDConf/alvaro-videla-building-a-distributed-data-ingestion-system-with-rabbitmq

A`lvaro Videla
co-author "RabbitMQ in Action"
http://alvaro-videla.com/


** Intro to RabbitMQ

Multi Protocol Messaging Server
Open Source (MPL)
Polyglot
Written in Erlang/OTP
Community Plugins

Multi Protocol: AMQP, MQTT, STOMP.
https://blogs.vmware.com/vfabric/2013/02/choosing-your-messaging-protocol-amqp-mqtt-or-stomp.html

Rebar is history, rabbitmq is pre-history. Not so easy to develop plugins.

Polyglot. Use can use it from: Java, node.js, Erlang, PHP, Ruby, .NET, Haskell, Python and many others.

RabbitMQ Simulator Demo
http://tryrabbitmq.com/
https://github.com/RabbitMQSimulator/RabbitMQSimulator

Есть много видов exchange, реализованых плагинами.
В том числе module hash exchange и consistent hash exchange.


** The Problem

Erlang code samples for producer and consumer.

Possible issues if not use rabbitmq but implement message queue. List of 6 points.

RabbitMQ Federation

можно построить разную топологию (дерево, кольцо и т.д.)

- support replication across different administrative domains
- support mix of erlang and rabbitmq versions
- support network partitions
- specificity - not everything has to be federated

Sample how to enable and configure.

expires, message-ttl, max-hops

Speed vs No Message Loss: ack-mode (on-confirm/on-publish/no-ack)

Recomended Reading:
Performance Modeling and Design of Computer Systems: Queueing Theory in Action
https://www.amazon.com/Performance-Modeling-Design-Computer-Systems/dp/1107027500


The Problem:
- Queues contents live in the node where the Queue was declared
- A cluster can access the queue from every connected node
- Queues are an Erlang processes
- Adding more nodes doesn't really help
(только я не понял, почему все перечисленое является проблемой)


** Solution

Sharded Queues
- declare queue with name nodename.queuename.index
- bind the queues to a partitioner exchange
- transparent to consumer (virtual queue name)

Federated Queues
- load-balance messages across federated queues
- only move messages when needed


* Очереди и блокировки. Теория и практика
https://habrahabr.ru/company/oleg-bunin/blog/316458/
Александр Календарев.
Уровень доклада низкий.

Один из способов связать frontend и backend сервера -- это очередь.

** Очередь средствами БД

*PostgreSQL*/*MySQL*:
- надежно
- медленно
- можно хранить историю

*MongoDB* -- быстрее, чем PostgreSQL/MySQL, но все равно медленно.

*Tarantool* -- хранит только в памяти. Если backend упал, то события в очереди накапливаются,
переполняется память, падает tarantool. Необходим мониторинг.

Можно мониторить длинну очереди. Если она больше обычной в 5-10 раз -- послать оповещение.
(Автор послает оповещение через telegram, т.к. это бесплатно, в отличие от SMS. На спичках экономит :)

Tarantool:
- репликация из коробки
- шардинг (дополнительный пакет)
- персистентность данных (нужно уточнять, т.к. выше сказано, что это in-memory хранилище)
- есть специальный пакет Queue
  - синхронная и асинхронная работа с очередями
  - очереди с приоритетом
  - ttl
  - ack

*Redis*:
- АПИ для работы со списками: RPUSH, LPOP
- синхронное и асинхронное АПИ
- in-memory
- нужен мониторинг, сделить за памятью
- персистентно (что ж такое "персистентно" для im-memory хранилища?)
- publish/subscribe

*MamecachedQ*:
- работает быстро
- невозможен мониторинг (не известна длина очереди)


** MQ Брокер

*ZeroMQ* — хорошее и быстрое решение, но это не брокер очередей.
Это просто API, т.е. мы соединяем одну точку с другой точкой (или с множеством точек).
Но здесь нет очередей, если одна из точек пропадет, то данные потеряются.

*Apache Kafka*
Высокопроизводительное решение из стека hadoop.
Нужно там, где есть большой поток данных и нужно его обработать.

Система потоковой обработки сообщений. Разрабатывалось для сбора логов.
Распределенная. С подтверждением доставки.
Требует синхронизации кластера через ZooKeeper.


** Протоколы

*STOMP* -- Simple (or Streaming) Text Oriented Message Protocol
- текстовый
- поверх HTTP или Websocket
- сообщение имеет тело и заголовок
- может быть разделено на фреймы
- publish/subscribe
- ack
- auth

*MQTT* -- Message Queue Telemetry Transport
- бинарный
- сообщение имеет тело и заголовок
- может быть разделено на фреймы
- publish/subscribe
- ack
- auth

*AMQP* -- Advanced Message Queuing Protocol
- exchange
  - name
  - type: fanout, direct, topic
  - props: autodelete, transit, durable
- queue
  - name
  - props: autodelete, durable
- bind
  - routing key
- message
  - body
  - routing key
  - headers
  - props


** RabbitMQ

Требует администрирования.
Требователен по памяти.
Можно объединять в кластер.
Много плагинов.


** Блокировки

И тут почему-то про Apacke ZooKeeper


* Принципы и приёмы обработки очередей
https://habrahabr.ru/company/oleg-bunin/blog/309332/
Константин Осипов

Для начала о себе — я занимаюсь разработкой СУБД Tarantool в Mail.ru.
Этот доклад будет об обработке очередей.
У нас много очередей внутри системы,
фактически вся база данных построена как система массового обслуживания.

В основном речь будет идти о проблемах балансировки нагрузки,
но перед этим я хотел бы поговорить о том,
зачем нужны очереди и как они появились именно в компьютерных системах, чего они позволяют добиться.

Одна из моих любимых мисконцепций по поводу баз данных — это то, что транзакций достаточно для всего.

Проблемы распределенной транзакции:
- нет отказоустойчивости
- не все части системы поддерживают rollback (например, диспенсер банкнот в банкомате)
- не все части системы работают идемпотентно

Очереди:
- отказоустойчивые
- добавляют идемпотентность

Очередь выступает в роли журнала. Отслеживает текущее состояние задачи.

Плюсы:
- клиент и сервер не зависят друг от друга
- состояние задачи всегда известно (тут скорее про Tarantool, чем про RabbitMQ)
- балансировка нагрузки
- приоритеты

Минусы:
- дополнительная сущность
- больше операций на задачу
- необходима персистентность

Одна из моих любимых тем — то, что люди склоняются к неперсистентным очередям,
потому что им кажется, что в их конкретной задаче неперсистентных очередей достаточно.
Например, Rabbit.
Хотя Rabbit может быть персистентным, но там персистентность связана с транзакционностью.

Речь же идет о надежной персистентности, т.е. как только у вас появляется очередь,
ее состояние — это фактически состояние вашей системы.
Если вы теряете это состояние, то у вас могут быть всякого рода аномалии, связанные с повторной обработкой задач,
т.е. кому-то рассылка пришла 2 раза, у кого-то фотография добавилась 2 раза,
у кого-то вообще не добавилась, потому что потерялась задача.

Поэтому очередь — это не какая-то отдельная компонента,
а база данных, которая выступает в роли очереди, т.е. она выполняет этот сценарий.
Это транзакционная система. В принципе самые правильные очереди. И такого рода очереди стоят дороже.

Одна задача может порождать множество задач.

Допустим, у вас зарегистрировался пользователь, что нужно сделать?
Послать уведомление его друзьям, загрузить какие-то его картинки, смс или рассылку ему послать…
У вас множество разнородных задач, связанных с одним действием,
и очередь может выступать в виде мультиплексора.


** Практика применения

"плохие" задачи. Долгие и ресурсоемкие задачи, которые могут быть целью DDoS атак.

Предположим, что у нас в момент регистрации нового пользователя есть большой объем работы, связанный с чем-то.
Что мы можем сделать? Мы можем загрузить этот веб-сайт большим количеством пустых регистраций.

Есть типичные антипаттерны, когда кто-то загружает битую картинку,
воркер ее берет, крэшится, за счет этого очередь считает, что задача не выполнена,
отдает ее другому воркеру, он ее снова берет, крэшится,
задача постоянно возвращается в очередь,
воркеры делают пустую работу, а полезную работу никто не делает.

У вас может возникнуть желание вернуть задачу в очередь с каким-то timeout’ом,
По истечении этого timeout’а, возможно, внешний мир изменится и задачу удастся выполнить…
И, в конце концов, если задачу не удалось выполнить в течение долгого времени,
то вам имеет смысл просто избавиться от этой задачи, пометить ее как невыполнимую и т.д.

Проблемы, которые нужно решать:
- таймауты выполнения
- повторное выполнение
- приоритеты
- зависимые задачи
- вложенные очереди
- зависшие воркеры


** Балансировка нагрузки

Задача, когда мы организуем обработку очереди — это сделать так,
чтобы у нас с одной стороны была высокая утилизация ресурсов,
с другой стороны мы максимально качественно обслуживали всех клиентов (низкое latency).

./img/saturation_point.png

В момент перегрузки происходит что-то, что не направлено так или иначе на непосредственное обслуживание клиентов,
а направлено на борьбу с перегрузками. Например, если взять базу данных, типичным примером в БД является
снижение нагрузки, снижение производительности при увеличении количества одновременно присутствующих в БД транзакций.
Появляется ожидание на блокировках и deadlock’и.
deadlock’и приводят к тому, что транзакции рестартуют и их нужно выполнять повторно.

Нас интересует построение такой системы, которая будет находиться в оптимальной части кривой,
т.е. она будет выполнять максимально возможное количество запросов,
при этом сохраняя свои тактико-технические характеристики.

latency и RPS — это не связанные вещи.
Т.е. наше желание максимизировать производительность системы
и наше желание максимизировать качество обслуживания — это противоречивые желания.

./img/saturation_point_latency.png
./img/saturation_point_rps.png

Есть 2 способа понять, как работает система массового обслуживания:
- моделирование (теория очередей)
- симуляция (нагрузочное тестирование).


*** Моделирование

Нотация Кендалла классифицирует все системы по шести показателям:
- А — распределение времени между прибытиями задач
  (количество задач в определенный момент времени следует по пуассоновскому закону, оно случайное)
- В — распределение времени обслуживания
  (В компьютерных системах более-менее фиксировано)
- С — количество серверов
- К — ёмкость системы обслуживания
  (очередь фиксированного размера, кто не успел не получает обслуживания)
- M — это популяция источника или общий объем
  (сколько у вас потенциальных клиентов. Не конкретно в этот момент времени, а потенциальных.)
- Z — принцип обслуживания (приоритеты и т.п.)

Закон Литтла
Q = R * W
Q - queue size (средняя длина очереди)
R - скорость поступления запросов (RPS)
W - время ожидания (в секундах)
Справедливо для любой системы в стабильном состоянии.

Например, 10К PRS, запрос обрабатывается за 1 мс, тогда средняя длина очереди будет 10.

Выводы из теории очередей:
- Среднее время выполнения запроса отличается от минимального пропорционально длине очереди.
  Если мы хотим увеличить утилизацию ресурсов (RPS), нужна большая длина очереди.
  А если хотим короткий latency, нужна маленькая длина.
- При приближении загрузки к 100% длина очереди может расти полиноминально
  (не знаю, что это значит)
- Единая очередь на несколько серверов позволяет снизить дисперсию (показатель B)
  и повысить утилизацию (RPS) при сохранении необходимого latency
- В распределенной системе W неизменно (в лучшем случае) или ухудшается.
  Чтобы справляться с ростом R, нужно увеличивать Q (число серверов и очередей).
- Для равномерного распределения нагрузки в распределенной системе нужно,
  чтобы очереди к разным узлам были примерно одного размера.


*** Симуляция

Измеряем:
- RPS
- время обработки одного запроса
- средняя длина очереди
- осциляция
Ищем причины задержек.

Постановка задачи:
у нас есть 10 серверов, время выполнения одной задачи равно 10 мс,
и мы хотим, чтоб наш средний latency при такой-то нагрузке был равен 20 мс.
Мы хотим, чтоб 99% задач обрабатывались в пределах 20 мс.

Обычно мы пишем бенчмарк, в котором наш скрипт создает случайную задачу,
посылает ее на сервер, получает результат, измеряет время, пишет в лог.
Если мы хотим найти точку насыщения, мы увеличиваем количество клиентов.

Чаще всего в этой ситуации нас интересует RPS — количество запросов в секунду — чем больше, тем лучше.
Почему это неправильно? В первую очередь, нас должно интересовать качество обслуживания.
И в заданном качестве обслуживания нужно добиваться максимального RPS.

Необходимо измерять распределение latency (гистограмма), а не среднее.
Оцениваем среднее, минимум, максимум и дисперсию.

Можно иметь высокий RPS, но часть клиентов будет иметь очень плохое обслуживание.
С чем это связано особенно в базах данных?
С какой-то периодической работой, которая большую часть бенчмарок просто не меряет.
Т.е. если у вас база данных раз в секунду засыпает и что-то делает,
то вы можете на своем бенчмарке этого даже не увидеть.

Допустим LSM дерево Lеvel DB может очень быстро обрабатывать запросы,
потом в какой-то момент произойдет процесс мержинга деревьев,
и время выполнения запросов снизится.
Вас, естественно, в конечной системе интересует худшее время.

Чтобы получить нормальное представление о качестве
нужно построить гистограмму распределения времени обслуживания по персентилям (percentile).
Т.е. у нас 90% запросов обслуживаются с таким-то latency,
10% — в пределах такой,
и какой-то маленький процент запросов — вообще уходит в потолок и для него время обслуживания очень высокое.

Нам нужно определить SLA, т.е. нам необходимо,
чтобы 90% запросов обслуживались за 1мс,
9,9% — в пределах 5 мс,
а для остальных у нас допустимо 10 мс.
После определения SLA нам нужно этого SLA добиться.


** Борьба с перегрузкой

Простой способ — это просто ограничить размер очереди, т.е. все кто не успел, не получают сервис.

Каскад очередей. Пример -- не факт, что пустят в бар, если он переполнен.
Для того, чтобы люди, которые присутствуют в баре, получали нормальный сервис, кто-то должен подождать снаружи.
Люди снаружи не используют ресурсы бара (стулья, время бармена и т.д.)

Backpressure -- более общая идея.
