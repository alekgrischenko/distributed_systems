* Scaling Erlang
http://inaka.net/blog/2011/10/07/scale-test-plan-simple-erlang-application/

Creating a scalable system is not a matter of just writing it in Erlang.


* Distributed erlang
http://emauton.org/disterl/

The protocol Erlang nodes use to communicate is described between the
[[http://www.erlang.org/doc/apps/erts/erl_dist_protocol.html][distribution protocol]] and [[http://www.erlang.org/doc/apps/erts/erl_ext_dist.html][external term format]] sections of the [[http://www.erlang.org/doc/apps/erts/users_guide.html][ERTS user guide]].



* Обсуждение riak_core

https://groups.google.com/forum/#!msg/erlang-russian/TVbVHhdS9lM/FLHGDrjAzbYJ

Valery Meleshkin:
   Плюсы:
   1) Куча всего уже сделана за вас и довольно качественно
   2) Каждый релиз riak привносит новый функционал, старый ломают крайне редко. Даже приватный API почти не ломают.
   3) Разработчики нормально общаются в твиторе и на GH (фиксят к сожалению не всегда оперативно)
   Минусы:
   1) Башо тестируют каждый релиз riak на определённых версиях OTP. Использовать другие версии будет затруднительно потому что их часто прибивают гвоздями в rebar.config.
   2) Многие депенды прибиты гвоздями к форкам basho, которые как правило отстают от апстрима. Но они постепенно отрезают такие депенды.
   Рекомендации
   1) Строго рекомендуется понимать что вы делаете и как это себя на самом деле ведёт (ownership и hinted handoff, forwarding во всех его ипостасях, разделения сети, ...)
   2) riak_core это AP система, хорошо подумайте подходит ли вам это. Если вам всё таки требуется CP — нужно кроме riak_core взять ещё и riak_ensemble.
   3) Пишите quickcheck/proper модели — это практически единственный способ что-то достоверно протестировать.
   4) Подпишитесь на репозитории basho на GH.
   5) Нормальный map-reduce называется riak_pipe.


* Про наше использование Riak
http://lionet.livejournal.com/98362.html

У нас 50 машин с десятком гигабайт памяти на каждой.
Используется InnoDB сторадж. Каждая машина почти упирается в диск на запись.

У нас этот кластер обслуживает несколько сотен гигабайт данных (сотни миллионов ключей),
в него происходит запись и чтение от нескольких сот до нескольких тысяч раз в секунду.

В течение месяца одна или две риаковских ноды обязательно выйдут из строя ...
Мы этих вылетов не замечаем, продакшн продолжает работать.
Так что операционно риак — это достаточно удобная сущность.
Ночью никого не будит, если хардвер слёг.

Проблемы же с риаком такие:

1. Довольно медленный map/reduce; почти не юзабельный на практике на больших данных.
   Кому нужен MR — используйте хадуп что-ли.

2. Links и link-walking — это шутка такая. Использовать её нельзя, если _максимальное_ количество линков больше чем примерно десяток.
   Графовую базу из риака не построишь.

3. Расширять кластер удобно от трёх до четырёх нод. Добавил ноду и всё.
   От десяти до пятидесяти нод расширять — это большой геморрой, ибо ребалансировка происходит долго
   (добавь ноду — балансируй, добавь другую — балансируй: это может длится неделями).
   В итоге нам пришлось заказывать платную помощь, которая нам расширила кластер, по сути, руками (полуавтоматически).

Весь датасет должен быть в памяти (у вас датасет на диске и всё ок? Так вам риак не особо нужен).


* Страх и ненависть в распределённых системах
https://habrahabr.ru/post/322876/

Распределённая система — это такая шутка, которая состоит из нескольких частей,
и эти части общаются друг с другом.
Но всё усложняется тем, что они общаются с задержками и с ошибками.

Пример из практики с записью одного значения в регистр.

CAP -- это теорема, которая формально не теорема, а эмпирическое правило, но все её называют теоремой.

Consistency. Существует порядка 50 видов целостности.
В CAP имеется в виду самый строгий из них -- линеаризуемость.
«Существует непротиворечивая история последовательных операций».

В реальном мире есть два выхода.
Вы можете либо сместиться в целостности и потерять доступность,
либо сместиться к доступности, но потерять целостность.

Есть много алгоритмов, которые реализуют различные системы CP / AP / AC.
Двухфазный коммит, Paxos, кворум и прочие рафты, Gossip и прочие кучи алгоритмов.

Пример master-slave репликации на Scala.

Jepsen – ое-фреймворк для тестирования распределённых систем. Написан на Clojure.
https://jepsen.io/
Набор готовых тестов для уже существующих баз данных, очередей и прочего. Вы всегда можете написать свой.
Куча статей о найденных проблемах, наверное, во всех базах данных https://aphyr.com/tags/jepsen

имитирует сетевые ошибки
генерирует случайные операции к вашей распределённой системе
сравнивает результат с эталонной моделью

Наша задача с тестом Jepsen — это писать в master, читать с
MasterSlave и понять, как обстоят дела с целостностью и правильно ли
мы написали нашу мастер/слейв репликацию или, может быть, нет.

Jepsen написан на Clojure, и тесты нужно писать тоже Clojure.
Если бы была возможность писать их на чём-нибудь другом, было бы классно.

3й пример -- консенсус. К-во нод которые подтвердили write, или отдали read.
На 5-ти секундном тесте все было хорошо. На 15-ти секундном вылезли проблемы.

PAXOS довольно сложный. Она написана математиком для математиков. Если
вы попытаетесь его реализовать, у вас будет очередная вариация
реализации PAXOS, которых очень много. Она не совсем для людей, она не
разбита на фазы. Это просто огромная портянка, описывающая
математические конструкции. Надо многое додумывать.

RAFT более новый, там учтены все проблемы, там описаны все те шаги,
которые нужно сделать, чтобы реализовать хороший алгоритм
консенсуса. Там всё классно. Есть огромное количество разных
реализаций.

Алгоритмы консенсуса используются много где, даже в третьей версии
MongoDB появился RAFT. В Cassandra всю жизнь был PAXOS. Во многих
базах данных, системах очередей, когда они дорастают до зрелости, рано
или поздно появляется алгоритм консенсуса.

Когда вы пишете свою распределённую систему есть много путей. Вы
должны знать, что эти пути есть и не делать еще один свой.
Каждый путь — это компромисс между целостностью, задержками, пропускной
способностью и прочими разными штуками.


* Сравнительный анализ методов балансировки трафика
https://habrahabr.ru/company/oleg-bunin/blog/319262/
Сергей Зубов

Обзорный доклад о балансировке трафика в высоконагруженных системах.

Цели:
- распределение нагрузки между серверами
- повышение отказоустойчивости
- защита от некоторых видов атак

Требования к системе балансировки:
- Справедливость -- любой запрос должен быть обслужен
- Эффективность -- равномерная загрузка ресурсов системы
- Сокращение latency
- Предсказуемость (не объяснено, вероятно речь о том, что узел для обработки запроса выбирается детерминировано, не случайно)
- Масштабируемость

Локальная -- внутри дата-центра
Глобальная -- между дата-центрами


** Локальная балансировка

- На канальном уровне
  - С применением отдельного балансировщика
  - С разделяемым адресом
- На сетевом уровне
- На транспортном уровне


*** Балансировка на канальном уровне

**** С применением отдельного балансировщика

Мы берем и навешиваем на некий специализированный интерфейс всех наших серверов
один и тот же IP-адрес нашего ресурса,
на который будут приходить запросы, и с которого будут уходить ответы.
Но на ARP-запрос с этого IP-адреса сервера не должны отвечать.

И мы навешиваем такой же IP-адрес на наш балансировщик, он будет отвечать на ARP запросы.
Т.о., получая запрос от клиента, наш балансировщик выбирает по определенному алгоритму тот или иной сервер,
который будет обрабатывать этот запрос, подменяет destination MAC
и отправляет его на обработку на данный сервер.

Сервер его у себя обрабатывает, и непосредственно, минуя балансировщик, отвечает клиенту через наш шлюз.


**** С разделяемым адресом

Нам необходимо превратить входящий unicast запрос в broadcast, либо в multicast, кто как хочет.

Все сервера должны на ARP запрос отвечать одним и тем же MAC-адресом,
т.е. это может быть либо несуществующий MAC-адрес, либо какой-то мультикастовый.
Либо мы можем навесить этот мультикастовый MAC-адрес на наш шлюз.

Соответственно, запрос приходит на наш ресурс, и шлюз его просто размножает ко всем серверам,
т.о. запросы поступают на все сервера одновременно,
и каждый сервер должен сам понимать, должен ли он отвечать на запрос или нет.
И понимать может очень просто, можно поставить, например, поставить деление на нуль srcIP, и дальше дело техники.


**** Плюсы и минусы

Плюсы:
- не зависит от протоколов вышележащих уровней
- обратный трафик в сторону клиента не нагружает балансировщик (в первом варианте)
- сокращение расходов при отказе от выделенного балансировищка (во втором варианте)
- используется только один публичный адрес
- быстрое добавление и удаление серверов в кластер

Минусы:
- необходимо размещать сервера в одном сегменте
- ограничение по входящей полосе (во втром варианте трафик идет на все сервера одновременно)

Решения:
- Linux Virtual Server

Обратный трафик в сторону клиента не нагружает балансировщик, что тоже хорошо,
например, для HTTP, когда у нас входящий запрос, как правило, легкий,
а ответ на него весит порой в десятки и сотни раз больше.

Публичные IP нынче дорогие.


*** Балансировка на сетевом уровне

Механизм довольно схожий с балансировкой на канальном уровне,
за одним единственным отличием — получая входящий запрос, наш балансировщик подменяет destination IP
на тот сервер, который будет обрабатывать запрос.
Сервер получает его, обрабатывает и должен передать его обратно балансировщику,
чтобы тот выполнил обратную подмену.

Плюсы:
- не зависит от протоколов высокого уровня
- один публичный адрес
- полная прозрачность работы для серверов (они не знают о существовании балансировщика)

Минусы:
- повышеная нагрузка на балансировщик за счет обратного трафика

Решения:
- Linux Virtual Server
- аппаратные реализации


*** Балансировка на транспортном уровне

Здесь тонкая грань, которая отличает балансировку на сетевом от балансировки на транспортном уровне.
В данном виде балансировки используются входящие порты источника и адресата.
(непонятно)

ECMP -- equal-cost multi-path.
Современные роутеры могут распределять нагрузку сами.
Для этого достаточно на роутер анонсировать одну и ту же подсеть по разным маршрутам.
Роутер, имея два одинаковых маршрута, по своим общим метрикам будет распределять нагрузку по ним равномерно.

Но существует ряд нюансов.

Пакеты в рамках одной TCP сессии должны попадать на один и тот же сервер.
(Такой режим на современных Cisco’ах называется perdestination и perflow и поддерживается по умолчанию)

Если мы пропишем на роутере статические маршруты,
то мы должны как-то автоматизировать процесс добавления и удаления серверов из нашего кластера.
Мы можем использовать различные протоколы маршрутизации, такие как BGP.

Плюсы:
- не зависит от протоколов высокого уровня
- один публичный адрес
- не нужно приобретать дополнительное оборудование

Минусы:
- нужно ставить на сервера дополнительный софт (BGP роутер)
- нет server-affinity
  (all HTTP requests from that client got to the same web server)
- все соединения разрываются при добавлении/удалении сервера
- ограниченое количество ECMP
- сервера должны быть одинаковые по производительности
- таймауты BGP протокола (если сервер вышел из строя, роутер какое-то время все еще шлет на него трафик)


** Глобальная балансировка

- DNS балансировка
  - DNS Round Robin
- Балансировка на прикладном уровне
  - Проксирование (Full Proxy)
  - Redirect запросов
- Балансировка на сетевом уровне
  - Anycast


*** DNS Round Robin

На DNS сервер просто добавляется несколько А-записей с разными IP-адресами всех наших серверов,
и сервер сам будет в цикличном порядке выдавать эти адреса.
Т.е. первый запрос получит первый сервер, второй запрос — второй сервер,
третий запрос — третий сервер, четвертый запрос — первый сервер и т.д.

Плюсы:
- независимость от протокола высокого уровня
- независимость от нагрузки (благодаря кеширующим DNS-серверам)
- универсальность (локальная и глобальная балансировка)
- низкая стоимость, быстрый старт

Минусы:
- сложно отключать сервера в случае выхода их из строя
  нужен двойной запас серверной мощности
  и резервирование по протоколу CARP или VRRP
- сложно распределять нагрузку в нужной пропорции
- каждый сервер должен иметь глобальный IP (а они дороги и ограничены)

Решения:
- любой DNS сервер, например Named


*** Full Proxy

Умный прокси. Балансировщик получает запрос к нашему ресурсу,
анализирует заголовки прикладного уровня, понимает какой ресурс нужен клиенту,
и направляет запрос на тот или иной сервер, на котором этот ресурс содержится.

Балансировщик может добавлять в заголовки HTTP, например,
информацию о том, с какого IP пришел клиент,
для того, чтобы сервер знал, куда его отправлять ответ, и с кем он работает.

Выполнив запрос, сервер передает его обратно на балансировщик,
тот выполняет необходимые манипуляции с новыми заголовками либо третьего уровня,
либо седьмого уровня и отдает его клиенту.

Плюсы:
- server affinity (родство)
- распределение разных типов запросов к разным серверам
- возможность анализировать и модифицировать запросы
- фильтрация запросов по URL (защита от разных атак)
- прокси может определять работоспособность каждого сервера

Минусы:
- необходимо балансировать нагрузку на сами балансировщики
- дополнительная точка отказа
- большое потребление ресурсов
- свой проски для каждого протокола

Решения:
- HAProxy
- nginx


*** Redirect запросов

Redirect запросов имеет довольно ограниченное применение —
в основном для глобальной балансировки, в частности, для HTTP.

Балансировщик отвечает редиректом на наш сервер, на котором содержатся ресурсы.
Например, получая запрос по HTTP, балансировщик отвечает  —  302 move temporary
с указанием адреса того сервера, на который дальше будет ходить наш клиент.

Плюсы:
- распределение запросов по разным серверам за счет анализа запроса

Минусы:
- малая применимость к протоколам высокого уровня
- увеличение времени отклика
- два запроса к сервису на каждый запрос клиента
  (например, клиент запрашивает какой-то контент, который порезан кусками,
  то на каждый кусок клиент будет выполнять по два запроса,
  что резко увеличивает время обслуживания клиента)

Решения:
- nginx


*** Anycast

Мы из разных географических участков анонсируем один и тот же префикс сети.
Таким образом, каждый запрос клиента будет маршрутизироваться
на ближайший к нему сервер (географически и топологически).

Плюсы:
- минимальные задержки при обработке запросов
- трафик через немагистральные каналы (удешевление)
- распределением нагрузки занимается сама сеть (интернет-провайдер)
- высокая отказоустойчивость
- легко добавлять/удалять сервера

Минусы:
- возможность перестроения маршрутов
  (критично для TCP-сессий, если часть пакетов уйдет на один сервер, другая часть на другой)
- невозможно протоколировать с какого узла обслуживается клиент
- дорогое оборудование
- интересы ISP (роутинг по более дешовым марштрутам, а не по коротким)


** Алгоритмы распределения нагрузки

Weighted Round Robin
Позволяет навесить на каждый сервер определенный весовой коэффициент,
который будет учитывать мощность и производительность сервера,
т.о. более производительный сервер будет получать запросы чаще.

Least Connection
Учитывается количество одновременных соединений с данным сервером в данный момент.
Можно сочетать с WRR.

Destination Hash Scheduling, Source Hash Scheduling
Анализируется IP-адрес либо источника, либо адресата
и выбирается из некой статической таблицы тот или иной сервер.

Sticky Sessions
Привязка клиента к определенному серверу,
все пакеты в рамках одной сессии будут ходить только на этот сервер.


* ==
