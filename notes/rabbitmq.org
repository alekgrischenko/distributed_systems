* 101 способ приготовления RabbitMQ и немного о pipeline архитектуре
https://habrahabr.ru/company/oleg-bunin/blog/310418/

Павел Филонов
(его же доклад "Выбираем СУБД для хранения временных рядов", я слушал в живую).

Отличие "события" и "запроса":

С request'ом всегда связан кто-то, кто сидит на той стороне,
тот, кто его отправил, очень нетерпеливый человек, робот, браузер, программа,
он ждет от нас ответа.

Система, которая засылает в нас события, логи, метрики, статистики –
От нас не требуют мгновенного ответа на какой-то вопрос.
От нас просят суметь много и быстро их обработать, обработать их по-разному.

Сколько эта технология проживет?
Если они так быстро появляются, то они начнут примерно с такой же скоростью умирать.

С этой точки зрения RabbitMQ интересен не как продукт, а как технология,
которая опирается на протокол AMQP, более низлежащий слой,
который уже нашел достаточно неплохое свое применение.

Пользователи AMQP:
- Google, вообще, выпускает официальный анонс, что он просто свой SQS-сервис баз строит на основе RabbitMQ.
- Microsoft Azure просто реализует протокол AMQP, реализация у них явно, похоже, своя.
- VMware – один из родоначальников протокола AMQP и системы RabbitMQ, очень активно использует его внутри своих решений.

Преимущества:
- Асинхронная обработка
- Простое добавление обработчиков
- Гибкая маршрутизация
- Удобная отладка
- Масштабируемость читателей и писателей
- Масштабируемость брокера (у RabbitMQ хорошо)
- Устойчивость к перезагрузкам и отказам

Topic в 3 раза медленее Direct.
Consistent Hash быстрый.
Преимущество в том, что он работает с числами. Первые три работают со строками как ключами маршрутизации, а последний работает с числами.

Пакетная обработка. Apache Kafka и ZeroMQ -- из коробки.
(prefetch count -- это не оно?)

Переполнение очередей. Закон Литтла.
- сохранение на диск (чтобы обработать потом)
- блокирование писателей (back-pressure)
- ограничьте размер очередей и/или время жизни сообщений (load-shredding)

Есть встроенный механизм RabbitMQ flow control.
https://www.rabbitmq.com/flow-control.html

Система начинает вставлять случайное ожидание, специальным образом
подобранное при чтении сокета от паблишера, в каком-то смысле уменьшая
уже даже на сетевом уровне интенсивность приходящих от него сетевых
пакетов.

The connection is being blocked and unblocked several times per
second, in order to keep the rate of message ingress at one that the
rest of the server can handle.
From the client's perspective it should just look like the network
bandwidth to the server is lower than it actually is.

Как только очередь возвращается в свои рамки, этот стоп-сигнал убирается, писатель начинает работать в прежнюю силу.

Если это было что-то пиковое, временное, это нас спасет.
Если нет, и эта ситуация постоянна,
мы ее откладываем до самой границы системы – до точки входа.

Stateless filters.
Stateful filters, сумматоры, разного рода агрегаторы.

Способы шардинга:
- остаток от деленая на к-во очередей. Требует константного количества очередей, нельзя добавить/убрать очередь.
- В RabbitMQ есть целых 2 Sharding plugin’а
- consistent-hash-exchange – идет прямо в дефолтной инсталляции,
реализует консистентного хэширования,
позволяет динамически менять количество очередей
старается делать так, чтобы решардинг прошел как можно более мягко.

* Alvaro Videla - Building a Distributed Data Ingestion System with RabbitMQ
https://www.youtube.com/watch?v=EUfSgYU_SFk
https://www.slideshare.net/HDConf/alvaro-videla-building-a-distributed-data-ingestion-system-with-rabbitmq


===
